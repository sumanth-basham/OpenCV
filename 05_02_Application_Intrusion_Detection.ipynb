{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "1e654b3bc3aace0335b326231d51e90ebd214a7f2d0629a648660f7deb4b3382"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tillu1208/OpenCV/blob/main/05_02_Application_Intrusion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIL3TYYcMucy"
      },
      "source": [
        "<h1 style=\"font-size:30px;\">Application: Intrusion Detection</h1>\n",
        "\n",
        "In this notebook, we are going to demonstrate how to build an intrusion detection application that monitors a surveillance video stream for unexpected behavior. If an intrusion is detected that portion of the video stream will be saved to preserve a record of the activity and could also trigger an alert notification. Topics covered in this notebook include:\n",
        "\n",
        "* Using a background subtraction model to isolate moving objects in the foreground (creating a foreground mask)\n",
        "* Using a method called \"erosion\" to remove noise from the foreground mask\n",
        "* Using contours to further identify the most prominent regions in the foreground subject\n",
        "\n",
        "![Intruder-detection](https://opencv.org/wp-content/uploads/2021/08/c0-m5-Feature-Image-02.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oenGLo7IMucy"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print(\"Downloading Code to Colab Environment\")\n",
        "    !wget https://www.dropbox.com/sh/vmzfc3wy5wwfrvi/AACY8uK6k6aTF5QJahLkAplta?dl=1 -O module-code.zip -q --show-progress\n",
        "    !unzip -qq module-code.zip\n",
        "    %cd Applications\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-YmRSjMucz"
      },
      "source": [
        "# 1. Work Flow\n",
        "\n",
        "* Create a background subtractor object using **`createBackgroundSubtractorKNN()`**\n",
        "* Apply the background subtractor to each video frame to create a foreground mask using the **`apply()`** method\n",
        "* Apply erosion to the foreground mask to reduce noise using **`erode()`**\n",
        "* Create contours from the eroded foreground mask using **`findContours()`**\n",
        "* Find the largest contour from the previous step using the **`sorted()`** function\n",
        "* Find the bounding rectangle of the largest contour using **`boundingRect()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p-M3OytMucz"
      },
      "source": [
        "# 2. Documentation Sumary from Previous Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vmnxhr3Mucz"
      },
      "source": [
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />\n",
        "\n",
        "### <font color=\"green\">OpenCV Documentation</font>\n",
        "\n",
        "[**`createBackgroundSubtractorKNN()`**](https://docs.opencv.org/4.5.2/de/de1/group__video__motion.html#gac9be925771f805b6fdb614ec2292006d)<br>\n",
        "[**`apply()`**](https://docs.opencv.org/4.5.2/d7/df6/classcv_1_1BackgroundSubtractor.html#aa735e76f7069b3fa9c3f32395f9ccd21)<br>\n",
        "[**`erode()`**](https://docs.opencv.org/4.5.2/d4/d86/group__imgproc__filter.html#gaeb1e0c1033e3f6b891a25d0511362aeb)<br>[**`findNonZero()`**](https://docs.opencv.org/4.5.2/d2/de8/group__core__array.html#gaed7df59a3539b4cc0fe5c9c8d7586190) <br>\n",
        "[**`boundingRect()`**](https://docs.opencv.org/4.5.2/d3/dc0/group__imgproc__shape.html#ga103fcbda2f540f3ef1c042d6a9b35ac7) <br>\n",
        "[**`findContours()`**](https://docs.opencv.org/4.5.2/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0) <br>\n",
        "[**`drawContours()`**](https://docs.opencv.org/4.5.2/d6/d6e/group__imgproc__draw.html#ga746c0625f1781f1ffc9056259103edbc)<br>\n",
        "[**`contourArea()`**](https://docs.opencv.org/4.5.2/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1)\n",
        "<hr style=\"border:none; height: 4px; background-color:#D3D3D3\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_OW91HcMucz"
      },
      "source": [
        "# 3. Create Video Capture and Video Writer Objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HQ8YsfXMucz"
      },
      "source": [
        "source = './intruder_1.mp4'\n",
        "\n",
        "video_cap = cv2.VideoCapture(source)\n",
        "if not video_cap.isOpened():\n",
        "    print('Unable to open: ' + source)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez8G-GI6Muc0"
      },
      "source": [
        "frame_w = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_h = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "size = (frame_w, frame_h)\n",
        "size_quad = (int(2*frame_w), int(2*frame_h))\n",
        "\n",
        "video_out_alert_file = 'video_out_alert_1.mp4'\n",
        "video_out_quad_file = 'video_out_quad_1.mp4'\n",
        "\n",
        "# Create video writer objects.\n",
        "video_out_alert = cv2.VideoWriter(video_out_alert_file, cv2.VideoWriter_fourcc(*'XVID'), fps, size)\n",
        "video_out_quad = cv2.VideoWriter(video_out_quad_file, cv2.VideoWriter_fourcc(*'XVID'), fps, size_quad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpXXaZ0OMuc0"
      },
      "source": [
        "# 4. Execution and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTjtlQVZMuc0"
      },
      "source": [
        "def drawBannerText(frame, text, banner_height_percent = 0.08, font_scale = 0.8, text_color = (0, 255, 0),\n",
        "                   font_thickness = 2):\n",
        "    # Draw a black filled banner across the top of the image frame.\n",
        "    # percent: set the banner height as a percentage of the frame height.\n",
        "    banner_height = int(banner_height_percent * frame.shape[0])\n",
        "    cv2.rectangle(frame, (0, 0), (frame.shape[1], banner_height), (0, 0, 0), thickness = -1)\n",
        "\n",
        "    # Draw text on banner.\n",
        "    left_offset = 20\n",
        "    location = (left_offset, int(10 + (banner_height_percent * frame.shape[0]) / 2))\n",
        "    cv2.putText(frame, text, location, cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color,\n",
        "                font_thickness, cv2.LINE_AA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Che-pFDyMuc0"
      },
      "source": [
        "### <font style=\"color:rgb(50,120,230)\">Create background subtraction object</font>\n",
        "The background subtraction object created below will be used to process each frame in the video stream."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9uBnR6zMuc1"
      },
      "source": [
        "bg_sub = cv2.createBackgroundSubtractorKNN(history = 200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFLRLsWVMuc1"
      },
      "source": [
        "### <font style=\"color:rgb(50,120,230)\">Process video for analysis</font>\n",
        "The code below contains extra logic required to produce an analysis video that contans four views."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsqQPR9IMuc1"
      },
      "source": [
        "ksize = (5, 5)        # Kernel size for erosion.\n",
        "max_contours = 3      # Number of contours to use for rendering a bounding rectangle.\n",
        "frame_count = 0\n",
        "frame_start = 5       # Allow this number of frames to bootstrap the generation of a background model.\n",
        "red    = (0, 0, 255)\n",
        "yellow = (0, 255, 255)\n",
        "green  = (0, 255, 0)\n",
        "\n",
        "# Quad view that will be built.\n",
        "#----------------------------------------\n",
        "# frame_fg_mask         :  frame\n",
        "# frame_fg_mask_erode_c :  frame_erode_c\n",
        "#----------------------------------------\n",
        "\n",
        "# Process video frames.\n",
        "while True:\n",
        "    ret, frame = video_cap.read()\n",
        "    frame_count += 1\n",
        "    if frame is None:\n",
        "        break\n",
        "    else:\n",
        "        frame_erode_c = frame.copy()\n",
        "\n",
        "    # Stage 1: Create a foreground mask for the current frame.\n",
        "    fg_mask = bg_sub.apply(frame)\n",
        "\n",
        "    # Wait a few frames for the background model to learn.\n",
        "    if frame_count > frame_start:\n",
        "\n",
        "        # Stage 1: Motion area based on foreground mask.\n",
        "        motion_area = cv2.findNonZero(fg_mask)\n",
        "        if motion_area is not None:\n",
        "            x, y, w, h = cv2.boundingRect(motion_area)\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), red, thickness=2)\n",
        "            drawBannerText(frame, 'Intrusion Alert', text_color=red)\n",
        "\n",
        "        # Stage 2: Stage 1 + Erosion.\n",
        "        fg_mask_erode_c = cv2.erode(fg_mask, np.ones(ksize, np.uint8))\n",
        "        motion_area_erode = cv2.findNonZero(fg_mask_erode_c)\n",
        "        if motion_area_erode is not None:\n",
        "            xe, ye, we, he = cv2.boundingRect(motion_area_erode)\n",
        "            cv2.rectangle(frame_erode_c, (xe, ye), (xe + we, ye + he), red, thickness=2)\n",
        "            drawBannerText(frame_erode_c, 'Intrusion Alert', text_color=red)\n",
        "\n",
        "        # Convert foreground masks to color so we can build a composite video with color annotations.\n",
        "        frame_fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
        "        frame_fg_mask_erode_c = cv2.cvtColor(fg_mask_erode_c, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        # Stage 3: Stage 2 + Contours.\n",
        "        contours_erode, hierarchy = cv2.findContours(fg_mask_erode_c, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if len(contours_erode) > 0:\n",
        "\n",
        "            # Annotate eroded foreground mask with cotours.\n",
        "            cv2.drawContours(frame_fg_mask_erode_c, contours_erode, -1, green, thickness=2)\n",
        "\n",
        "            # Sort contours based on area.\n",
        "            contours_sorted = sorted(contours_erode, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "            # Compute bounding rectangle for the top N largest contours.\n",
        "            for idx in range(min(max_contours, len(contours_sorted))):\n",
        "                xc, yc, wc, hc = cv2.boundingRect(contours_sorted[idx])\n",
        "                if idx == 0:\n",
        "                    x1 = xc\n",
        "                    y1 = yc\n",
        "                    x2 = xc + wc\n",
        "                    y2 = yc + hc\n",
        "                else:\n",
        "                    x1 = min(x1, xc)\n",
        "                    y1 = min(y1, yc)\n",
        "                    x2 = max(x2, xc + wc)\n",
        "                    y2 = max(y2, yc + hc)\n",
        "\n",
        "            # Draw bounding rectangle for top N contours on output frame.\n",
        "            cv2.rectangle(frame_erode_c, (x1, y1), (x2, y2), yellow, thickness=2)\n",
        "            drawBannerText(frame_erode_c, 'Intrusion Alert', text_color=red)\n",
        "\n",
        "        # Annotate each video frame.\n",
        "        drawBannerText(frame_fg_mask, 'Foreground Mask')\n",
        "        drawBannerText(frame_fg_mask_erode_c, 'Foreground Mask (Eroded + Contours)')\n",
        "\n",
        "        # Build quad view.\n",
        "        frame_top = np.hstack([frame_fg_mask, frame])\n",
        "        frame_bot = np.hstack([frame_fg_mask_erode_c, frame_erode_c])\n",
        "        frame_composite = np.vstack([frame_top, frame_bot])\n",
        "\n",
        "        # Annotate quad view with dividers.\n",
        "        fc_h, fc_w, _= frame_composite.shape\n",
        "        cv2.line(frame_composite, (int(fc_w/2), 0), (int(fc_w/2), fc_h), yellow , thickness=3, lineType=cv2.LINE_AA)\n",
        "        cv2.line(frame_composite, (0, int(fc_h/2)), (fc_w, int(fc_h/2)), yellow, thickness=3, lineType=cv2.LINE_AA)\n",
        "\n",
        "        # Write video output files.\n",
        "        video_out_alert.write(frame_erode_c)    # Alert\n",
        "        video_out_quad.write(frame_composite)   # Analysis quad view\n",
        "\n",
        "video_cap.release()\n",
        "video_out_alert.release()\n",
        "video_out_quad.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmscSfPPMuc2"
      },
      "source": [
        "### <font style=\"color:rgb(50,120,230)\">Load Analysis Video</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "za59lFTWMuc2"
      },
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Load output analysis video.\n",
        "clip = VideoFileClip(video_out_quad_file)\n",
        "clip.ipython_display(width = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvfrS42-Muc2"
      },
      "source": [
        "### <font style=\"color:rgb(50,120,230)\">Load Alert Video</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F3qU8GpMuc2"
      },
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Load output video.\n",
        "clip = VideoFileClip(video_out_alert_file)\n",
        "clip.ipython_display(width=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a546dT2oMuc3"
      },
      "source": [
        "# 5. Application Code\n",
        "The code below has been simplified to only include the portions required to produce the final alert video. However, an additional step has been added that checks the size of the largest contour in the eroded foreground mask relative to an input threshold fraction of the total frame area. The purpose of this threshold check is to help minimize false positives by requiring that the largest contour exceeds a certain fraction of the total frame area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drP7GNZwMuc3"
      },
      "source": [
        "source = './intruder_2.mp4'  # Or specify 'source' as the index associated with your camera system.\n",
        "\n",
        "video_cap_2 = cv2.VideoCapture(source)\n",
        "if not video_cap_2.isOpened():\n",
        "    print('Unable to open: ' + source)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRB1nTQRMuc3"
      },
      "source": [
        "frame_w = int(video_cap_2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_h = int(video_cap_2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(video_cap_2.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "size = (frame_w, frame_h)\n",
        "frame_area = frame_w * frame_h\n",
        "\n",
        "video_out_alert_file_2 = 'video_out_alert_2.mp4'\n",
        "video_out_alert_2 = cv2.VideoWriter(video_out_alert_file_2, cv2.VideoWriter_fourcc(*'XVID'), fps, size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXJzwhXJMuc3"
      },
      "source": [
        "bg_sub = cv2.createBackgroundSubtractorKNN(history=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFlLk0knMuc3"
      },
      "source": [
        "ksize = (5, 5)        # Kernel size for erosion.\n",
        "max_contours = 3      # Number of contours to use for rendering a bounding rectangle.\n",
        "frame_count = 0\n",
        "min_contour_area_thresh = 0.01 # Minimum fraction of frame required for maximum contour.\n",
        "\n",
        "yellow = (0, 255, 255)\n",
        "red = (0, 0, 255)\n",
        "\n",
        "# Process video frames.\n",
        "while True:\n",
        "\n",
        "    ret, frame = video_cap_2.read()\n",
        "    frame_count += 1\n",
        "    if frame is None:\n",
        "        break\n",
        "\n",
        "    # Stage 1: Create a foreground mask for the current frame.\n",
        "    fg_mask = bg_sub.apply(frame)\n",
        "\n",
        "    # Stage 2: Stage 1 + Erosion.\n",
        "    fg_mask_erode = cv2.erode(fg_mask, np.ones(ksize, np.uint8))\n",
        "\n",
        "    # Stage 3: Stage 2 + Contours.\n",
        "    contours_erode, hierarchy = cv2.findContours(fg_mask_erode, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if len(contours_erode) > 0:\n",
        "\n",
        "        # Sort contours based on area.\n",
        "        contours_sorted = sorted(contours_erode, key = cv2.contourArea, reverse=True)\n",
        "\n",
        "        # Contour area of largest contour.\n",
        "        contour_area_max = cv2.contourArea(contours_sorted[0])\n",
        "\n",
        "        # Compute fraction of total frame area occupied by largest contour.\n",
        "        contour_frac = contour_area_max / frame_area\n",
        "\n",
        "        # Confirm contour_frac is greater than min_contour_area_thresh threshold.\n",
        "        if contour_frac > min_contour_area_thresh:\n",
        "\n",
        "            # Compute bounding rectangle for the top N largest contours.\n",
        "            for idx in range(min(max_contours, len(contours_sorted))):\n",
        "                xc, yc, wc, hc = cv2.boundingRect(contours_sorted[idx])\n",
        "                if idx == 0:\n",
        "                    x1 = xc\n",
        "                    y1 = yc\n",
        "                    x2 = xc + wc\n",
        "                    y2 = yc + hc\n",
        "                else:\n",
        "                    x1 = min(x1, xc)\n",
        "                    y1 = min(y1, yc)\n",
        "                    x2 = max(x2, xc + wc)\n",
        "                    y2 = max(y2, yc + hc)\n",
        "\n",
        "            # Draw bounding rectangle for top N contours on output frame.\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), yellow, thickness = 2)\n",
        "            drawBannerText(frame, 'Intrusion Alert', text_color = red)\n",
        "\n",
        "            # Write alert video to file system.\n",
        "            video_out_alert_2.write(frame)\n",
        "\n",
        "video_cap_2.release()\n",
        "video_out_alert_2.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-9wL0wpQMuc3"
      },
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Load output video.\n",
        "clip = VideoFileClip(video_out_alert_file_2)\n",
        "clip.ipython_display(width = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}